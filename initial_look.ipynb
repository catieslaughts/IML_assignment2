{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac46ac4c",
   "metadata": {},
   "source": [
    "## A notebook just to take an initial look at the data for IML assignment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cddec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import astropy\n",
    "import astropy.units as u\n",
    "import astropy.coordinates as coord\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import umap.umap_ as umap \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import FastICA\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn import ensemble\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "import time\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60ad58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def read_in_data(filename = 'data/A2_data.csv'):\n",
    "#     '''reads in the data from the given csv, and saves it in a Pandas dataframe'''\n",
    "#     df = pd.read_csv(filename)\n",
    "    \n",
    "#     return df\n",
    "\n",
    "def resplit(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.33)#, random_state=92\n",
    "    X_train,y_train=X_train.reset_index(drop=True),y_train.reset_index(drop=True)\n",
    "    X_test,y_test=X_test.reset_index(drop=True),y_test.reset_index(drop=True)\n",
    "    return (X_train, X_test, y_train, y_test)\n",
    "\n",
    "def feature_importances_plot(forest, X_data, title = 'Feature Importances Using MDI', ymax = None):\n",
    "    importances = forest.feature_importances_\n",
    "    std = np.std([tree.feature_importances_ for tree in forest.estimators_], axis=0)\n",
    "\n",
    "    feature_names = X_data.columns\n",
    "    forest_importances = pd.Series(importances, index=feature_names)\n",
    "\n",
    "    x_locs = range(importances.size)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    forest_importances.plot.bar(yerr=std, ax=ax, capsize = 3)\n",
    "    \n",
    "    ax.set_title(title)\n",
    "    ax.set_ylabel('Mean Decrease in Impurity')\n",
    "    ax.set_ylim(0,ymax)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272c1cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/\"\n",
    "\n",
    "data=pd.read_csv(path+'A2_data.csv')\n",
    "\n",
    "X,y= data.loc[:, data.columns != 'class'], data['class']\n",
    "\n",
    "#We know that a flux should be positive so remove the datapoint which does not have that\n",
    "#This datapoint has value -9999 so not a detection but a instrumentation issue\n",
    "I_remove=np.where(X['u']<0)[0]\n",
    "X,y = X.drop(I_remove),y.drop(I_remove)\n",
    "X,y=X.reset_index(drop=True),y.reset_index(drop=True)\n",
    "\n",
    "corr_X = X.copy()\n",
    "coor_y = y.copy()\n",
    "\n",
    "print(f'There are {X.shape[0]} samples of each {X.shape[1]} features')\n",
    "\n",
    "#Data includes some identifiers lets remove those \n",
    "ID_parameters= ['field_ID','MJD','plate','alpha','delta']#'field_ID','MJD','plate', 'alpha', 'delta'\n",
    "for ID in ID_parameters:\n",
    "    X=X.loc[:, X.columns != ID]\n",
    "\n",
    "print(f'There are final {X.shape[0]} samples of now {X.shape[1]} features')\n",
    "\n",
    "X_train, X_test, y_train, y_test = resplit(X,y)\n",
    "\n",
    "print(f'There are {X_train.shape[0]} training samples of each {X_train.shape[1]} features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e4b01b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plt.scatter(data['alpha'][data['class']=='GALAXY'], data['delta'][data['class']=='GALAXY'], s = 5)\n",
    "# plt.scatter(data['alpha'][data['class']=='QSO'], data['delta'][data['class']=='QSO'], s = 5)\n",
    "# plt.scatter(data['alpha'][data['class']=='STAR'], data['delta'][data['class']=='STAR'], s = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5847d6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "ra = coord.Angle(data['alpha']*u.degree)\n",
    "ra = ra.wrap_at(180*u.degree)\n",
    "dec = coord.Angle(data['delta']*u.degree)\n",
    "\n",
    "new_df_arr = np.array([ra,dec,data['class']])\n",
    "plot_df = pd.DataFrame(np.transpose(new_df_arr), columns = ['ra','dec','class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedda8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(8,6))\n",
    "# ax = fig.add_subplot(projection=\"mollweide\")\n",
    "\n",
    "# for cls in ['GALAXY', 'QSO', 'STAR']:\n",
    "#     ra_sub = plot_df.loc[plot_df['class'] == cls, 'ra']*u.degree.to(u.rad)\n",
    "#     dec_sub = plot_df.loc[plot_df['class'] == cls, 'dec']*u.degree.to(u.rad)\n",
    "    \n",
    "#     ax.scatter(ra_sub, dec_sub, s = 5, label = cls)\n",
    "#     ax.set_xticklabels(['14h','16h','18h','20h','22h','0h','2h','4h','6h','8h','10h'])\n",
    "#     ax.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7b03de",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,12))\n",
    "colors = ['red', 'green', 'blue']\n",
    "\n",
    "for idx, cls in enumerate(['GALAXY', 'QSO', 'STAR']):\n",
    "    loc = 311+idx\n",
    "    ax = fig.add_subplot(loc, projection=\"mollweide\")\n",
    "    ra_sub = plot_df.loc[plot_df['class'] == cls, 'ra']*u.degree.to(u.rad)\n",
    "    dec_sub = plot_df.loc[plot_df['class'] == cls, 'dec']*u.degree.to(u.rad)\n",
    "    \n",
    "    ax.scatter(ra_sub, dec_sub, s = 5, c=colors[idx])\n",
    "    ax.set_xticklabels(['14h','16h','18h','20h','22h','0h','2h','4h','6h','8h','10h'])\n",
    "    ax.grid(True)\n",
    "    ax.set_title(cls)\n",
    "    \n",
    "plt.tight_layout()    \n",
    "#plt.savefig('./figures/skymaps.pdf', dpi=300, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719b9aa8",
   "metadata": {},
   "source": [
    "### CMDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a610a044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(6,6))\n",
    "\n",
    "# colors = ['red', 'green', 'blue']\n",
    "\n",
    "# for idx, cls in enumerate(['GALAXY', 'QSO', 'STAR']):\n",
    "#     loc = 221+idx\n",
    "#     ax = fig.add_subplot(loc)\n",
    "#     ra_sub = plot_df.loc[plot_df['class'] == cls, 'ra']*u.degree.to(u.rad)\n",
    "#     dec_sub = plot_df.loc[plot_df['class'] == cls, 'dec']*u.degree.to(u.rad)\n",
    "    \n",
    "#     color = data.loc[data['class'] == cls, 'g'] - data.loc[data['class'] == cls, 'r']\n",
    "#     mag = data.loc[data['class'] == cls, 'g']\n",
    "#     ax.scatter(color, mag, s = 5, c=colors[idx])\n",
    "    \n",
    "#     ax.set_xlim(-12,12)\n",
    "#     ax.set_ylim(10,35)\n",
    "#     ax.set_title(cls)\n",
    "#     ax.set_xlabel('g-r')\n",
    "#     ax.set_ylabel('g')\n",
    "    \n",
    "#     plt.gca().invert_yaxis()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136b2c24",
   "metadata": {},
   "source": [
    "### Correlation Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbbd591",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = X.corr()\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(corr,cmap='coolwarm', vmin=-1, vmax=1)\n",
    "fig.colorbar(cax)\n",
    "ticks = np.arange(0,len(X.columns),1)\n",
    "ax.set_xticks(ticks)\n",
    "plt.xticks(rotation=90)\n",
    "ax.set_yticks(ticks)\n",
    "ax.set_xticklabels(X.columns)\n",
    "ax.set_yticklabels(X.columns)\n",
    "ax.set_title('Feature Correlation Plot', y = -0.1)\n",
    "plt.savefig('./figures/correlationplot.pdf', dpi=300, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c07d204",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairplot_data = X.copy()\n",
    "pairplot_data['class'] = y\n",
    "color_pallete = {\n",
    "    'GALAXY' : 'red',\n",
    "    'QSO' : 'green',\n",
    "    'STAR' : 'blue'\n",
    "    \n",
    "}\n",
    "\n",
    "sns.pairplot(pairplot_data, hue = 'class', palette = color_pallete)\n",
    "#plt.savefig('./figures/pairplot.pdf', dpi=300, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1057add3",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4470735b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = resplit(X,y)\n",
    "\n",
    "# # X_train_temp,X_test_temp= X_train[cols], X_test[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841669ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree_clf = tree.DecisionTreeClassifier()\n",
    "# tree_clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504380dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8e5ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree.plot_tree(clf, max_depth = 0);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501679ea",
   "metadata": {},
   "source": [
    "### Random Forest Ensemble:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428211b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_ens = ensemble.RandomForestClassifier(n_estimators = 10, max_depth = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5189c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_ens.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5372a1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ens.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034f6bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_importances_plot(ens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd6fef6",
   "metadata": {},
   "source": [
    "## Cross-Validation on random tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecedd050",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = resplit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b5b4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_clf = tree.DecisionTreeClassifier()\n",
    "# tree_clf.fit(X_train, y_train)\n",
    "# tree_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae311c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_output = cross_validate(tree_clf, X_train, y_train, cv=5, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09b0cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Simple cross-validation yields average %0.5f accuracy +/- %0.5f\" % (cv_output['test_score'].mean(), cv_output['test_score'].std()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6567fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxdepth = np.arange(1, 21, 1)\n",
    "#maxdepth[0]+=1\n",
    "\n",
    "valmeans = []\n",
    "valstds = []\n",
    "\n",
    "trameans = []\n",
    "trastds = []\n",
    "\n",
    "for idx, depth in enumerate(maxdepth):\n",
    "    clf_tree = tree.DecisionTreeClassifier(max_depth = depth)\n",
    "    cv_output = cross_validate(clf_tree, X_train, y_train, cv=5, return_train_score=True)\n",
    "    \n",
    "    trameans.append(cv_output['train_score'].mean())\n",
    "    trastds.append(cv_output['train_score'].std())   \n",
    "    \n",
    "    valmeans.append(cv_output['test_score'].mean())\n",
    "    valstds.append(cv_output['test_score'].std()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364aa602",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(maxdepth, trameans, yerr=trastds, ecolor = 'black', capsize = 3, label = 'Training')\n",
    "plt.errorbar(maxdepth, valmeans, yerr=valstds, ecolor = 'black', capsize = 3, label = 'Validation')\n",
    "plt.xticks(maxdepth[1:])\n",
    "plt.title('Max Depth vs. Accuracies')\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend();\n",
    "\n",
    "#plt.savefig('./figures/trainvsvalidation.pdf', dpi=300, bbox_inches = 'tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4b6c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(14,8))\n",
    "\n",
    "# xlabels = ['1st', '2nd', '3rd', '4th', '5th']\n",
    "# x_axis_locs = np.arange(len(xlabels))\n",
    "# maxdepth = [4, 10, 20, None]\n",
    "\n",
    "# for idx, depth in enumerate(maxdepth):\n",
    "#     clf_tree = tree.DecisionTreeClassifier(max_depth = depth)\n",
    "#     cv_output = cross_validate(clf_tree, X_train, y_train, cv=5, return_train_score=True)\n",
    "    \n",
    "# #     clf_tree.fit(X_train,y_train)\n",
    "# #     test_score = clf_tree.score(X_test, y_test)\n",
    "#     print('max_depth = '+ str(depth)+' mean training score: %0.4f +/- %0.4f' % (cv_output['train_score'].mean(), cv_output['train_score'].std()))\n",
    "#     print('max_depth = '+ str(depth)+' mean validation score: %0.4f +/- %0.4f' % (cv_output['test_score'].mean(), cv_output['test_score'].std()))\n",
    "    \n",
    "#     loc = 221+idx\n",
    "#     ax = fig.add_subplot(loc)\n",
    "    \n",
    "#     ax.bar(x_axis_locs-.26, cv_output['train_score'], width=.25, label = 'Training Score')\n",
    "#     ax.bar(x_axis_locs, cv_output['test_score'], width=.25, label = 'Validation Score')\n",
    "# #     ax.bar(x_axis_locs+.26, test_score, width=.25, color='green', label = 'Test Score')\n",
    "\n",
    "#     ax.set_xticks(x_axis_locs, xlabels)\n",
    "#     ax.set_xlabel('Fold Number', fontsize=14)\n",
    "#     ax.set_ylabel('Accuracy', fontsize=14)\n",
    "#     ax.set_title('max_depth = ' + str(depth))\n",
    "#     ax.set_ylim(0,1.05)\n",
    "#     ax.legend()\n",
    "    \n",
    "# plt.suptitle('Training vs. Validation')\n",
    "# plt.tight_layout()\n",
    "\n",
    "# #plt.savefig('./figures/trainvsvalidation.pdf', dpi=300, bbox_inches = 'tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49126fad",
   "metadata": {},
   "source": [
    "# Hyper-parameter Tuning via Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e2f123",
   "metadata": {},
   "outputs": [],
   "source": [
    "red_data=pd.read_csv(path+'PCA_reduced_5.csv') #read in data\n",
    "\n",
    "red_X,red_y= red_data.loc[:, red_data.columns != 'class'], red_data['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5df3c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create training/test data for GSCV\n",
    "print(f'There are total {red_X.shape[0]} samples of {red_X.shape[1]} features')\n",
    "\n",
    "X_train, X_test, y_train, y_test = resplit(red_X,red_y)\n",
    "\n",
    "print(f'There are {X_train.shape[0]} training samples of each {X_train.shape[1]} features')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0aa5d96",
   "metadata": {},
   "source": [
    "### Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94a2ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create correlation plot of data (if data is PCA reduced, the plot should show no correlation)\n",
    "\n",
    "corr = red_X.corr()\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(corr,cmap='coolwarm', vmin=-1, vmax=1)\n",
    "fig.colorbar(cax)\n",
    "ticks = np.arange(0,len(red_X.columns),1)\n",
    "ax.set_xticks(ticks)\n",
    "plt.xticks(rotation=90)\n",
    "ax.set_yticks(ticks)\n",
    "ax.set_xticklabels(red_X.columns)\n",
    "ax.set_yticklabels(red_X.columns)\n",
    "ax.set_title('Feature Correlation Plot', y = -0.1)\n",
    "#plt.savefig('./figures/reducedcorrelationplot.pdf', dpi=300, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f102da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates a neat little pairplot of the data, useful for visualization, though takes a bit to run\n",
    "pairplot_data = red_data\n",
    "pairplot_data['class'] = y\n",
    "color_pallete = {\n",
    "    'GALAXY' : 'red',\n",
    "    'QSO' : 'green',\n",
    "    'STAR' : 'blue'\n",
    "    \n",
    "}\n",
    "\n",
    "sns.pairplot(pairplot_data, hue = 'class', palette = color_pallete)\n",
    "#plt.savefig('./figures/reducedpairplot.pdf', dpi=300, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0aa8bad",
   "metadata": {},
   "source": [
    "## Conduct GSCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4eb4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 5 #number of features in the reduced data set\n",
    "\n",
    "params = { #dictionary of possible parameters\n",
    "    'criterion':  ['gini', 'entropy'],\n",
    "    'max_depth':  [6,7,8,9,10],\n",
    "    'max_features': np.linspace(1,n_features,3).astype(int).tolist(), #for a 5-feature dataset, this gives [1,3,5]\n",
    "    'max_samples': [.25,.5,.75,1.],\n",
    "    'n_estimators': [150]\n",
    "}\n",
    "\n",
    "forest_clf = GridSearchCV(estimator=ensemble.RandomForestClassifier(), param_grid=params, cv=5, n_jobs=5, verbose=1, \n",
    "                   return_train_score = True) #create gridsearchcv\n",
    "\n",
    "forest_clf.fit(X_train, y_train)\n",
    "forest_clf.best_params_ #output \"best\" parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92166ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull out important info.\n",
    "params_df = pd.DataFrame(forest_clf.cv_results_['params'])\n",
    "validation_df = pd.DataFrame(forest_clf.cv_results_['mean_test_score'], columns=['Validation'])\n",
    "training_df = pd.DataFrame(forest_clf.cv_results_['mean_train_score'], columns=['Training'])\n",
    "\n",
    "#put into single dataframe\n",
    "gscv_output = pd.concat([params_df,validation_df,training_df],axis=1)\n",
    "#calculate percent difference\n",
    "gscv_output['Percent Difference'] = (gscv_output['Training'] - gscv_output['Validation'])/gscv_output['Training']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337e06d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save output dataframe, if wanted\n",
    "#gscv_output.to_csv('data/reducedcrosscor_out.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f854dd",
   "metadata": {},
   "source": [
    "### Select Parameter Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb68c0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bounds on the reduced hypothesis space\n",
    "minsearch = 0\n",
    "maxsearch = .05\n",
    "\n",
    "#create histogram of percent differences\n",
    "plt.hist(gscv_output['Percent Difference'], bins = 40);\n",
    "#plt.axvline(minsearch, c='grey', linestyle = 'dashed')\n",
    "plt.axvline(maxsearch, c='grey', linestyle = 'dashed', label = 'Max boundary')\n",
    "plt.title('Histogram of Percent Differences')\n",
    "plt.xlabel('Percent Difference')\n",
    "plt.ylabel('Count')\n",
    "plt.legend()\n",
    "\n",
    "# plt.savefig('./figures/meanDiffHist.pdf', dpi=300, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e7bf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose best parameters from this space\n",
    "selected_best = gscv_output.loc[(gscv_output['Percent Difference'] > minsearch) & (gscv_output['Percent Difference'] < maxsearch)].iloc[[gscv_output.loc[(gscv_output['Percent Difference'] > minsearch) & (gscv_output['Percent Difference'] < maxsearch), 'Validation'].argmax()]]\n",
    "selected_idx = selected_best.index.item() #index needed for later visualization\n",
    "\n",
    "#grab the \"best\" parameters from gscv, in case wanted for comparison\n",
    "gscv_best = gscv_output.loc[(gscv_output['criterion'] == forest_clf.best_params_['criterion']) & (gscv_output['max_depth'] == forest_clf.best_params_['max_depth']) & (gscv_output['max_features'] == forest_clf.best_params_['max_features']) & (gscv_output['max_samples'] == forest_clf.best_params_['max_samples'])]\n",
    "gscv_idx = gscv_best.index.item()#index needed for later visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8573d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dictionary of selected parameters\n",
    "selected_params = {'criterion': selected_best['criterion'].item(),\n",
    "                   'max_depth': int(selected_best['max_depth'].item()),\n",
    "                   'max_features': selected_best['max_features'].item(), \n",
    "                   'max_samples' : selected_best['max_samples'].item(),\n",
    "                   'n_estimators': selected_best['n_estimators'].item()}\n",
    "\n",
    "#create random forest\n",
    "selected = ensemble.RandomForestClassifier(**selected_params)\n",
    "\n",
    "selected_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2529d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#grab GSCV \"best\" params\n",
    "gscv_params = forest_clf.best_params_\n",
    "gscv = ensemble.RandomForestClassifier(**gscv_params)\n",
    "\n",
    "gscv_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e440c9d2",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b56649c",
   "metadata": {},
   "outputs": [],
   "source": [
    "showGSCV = False \n",
    "#Toggles whether plots are made showing the outputs from the GSCV's selected \"best\" parameter set, given\n",
    "#that the \"best\" set is different from the one selected in our reduced hypothesis space\n",
    "\n",
    "gscv_params == selected_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8399251",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the training and validation scores by index for all 120 options\n",
    "\n",
    "plt.plot(np.arange(len(gscv_output['Training'])), gscv_output['Training'], label = 'Training')\n",
    "plt.plot(np.arange(len(gscv_output['Validation'])), gscv_output['Validation'], label = 'Validation')\n",
    "#plt.plot(np.arange(len(gscv_output['Percent Difference'])), gscv_output['Percent Difference'], label = 'Percent Difference')\n",
    "\n",
    "plt.axvline(selected_idx, c='darkgrey', linestyle = 'dashed', label = 'Selected Best Parameters')\n",
    "if gscv_params != selected_params and showGSCV:\n",
    "    plt.axvline(gscv_idx, c='grey', linestyle = 'dotted', label = 'GSCV Parameters')\n",
    "\n",
    "plt.title('Training and Validation Mean Score for All Parameter Combinations')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(.7,1.01)\n",
    "plt.legend();\n",
    "\n",
    "#plt.savefig('./figures/scoresLinePlot.pdf', dpi=300, bbox_inches = 'tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6293307a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14,8))\n",
    "\n",
    "xlabels = ['gini','entropy']\n",
    "x_axis_locs = np.arange(len(xlabels))\n",
    "parameterlist = ['criterion', 'max_depth', 'max_features', 'max_samples']\n",
    "\n",
    "for idx, param in enumerate(parameterlist):\n",
    "    loc = 221+idx\n",
    "    ax = fig.add_subplot(loc)\n",
    "    \n",
    "    tra_means = []\n",
    "    tra_stds = []\n",
    "    val_means = []\n",
    "    val_stds = []\n",
    "    for value in gscv_output[param].unique():\n",
    "        tra_means.append(gscv_output[gscv_output[param] == value]['Training'].mean())\n",
    "        tra_stds.append(gscv_output[gscv_output[param] == value]['Training'].std())\n",
    "        val_means.append(gscv_output[gscv_output[param] == value]['Validation'].mean())\n",
    "        val_stds.append(gscv_output[gscv_output[param] == value]['Validation'].std())\n",
    "    \n",
    "    if idx == 0:\n",
    "        #ax.bar(x_axis_locs-.24, tra_means, width=.47, label = 'Training Score', yerr = tra_stds, capsize = 3)\n",
    "        ax.bar(x_axis_locs, val_means, width=.99, label = 'Validation Score', yerr = val_stds, capsize = 3)\n",
    "        ax.set_xticks(x_axis_locs, xlabels)\n",
    "        ax.set_ylim(0.82,0.92)\n",
    "    \n",
    "    else:\n",
    "        #ax.errorbar(gscv_output[param].unique(), tra_means, label = 'Training Score')#, yerr = tra_stds, capsize = 3,ecolor='black')\n",
    "        ax.errorbar(gscv_output[param].unique(), val_means, label = 'Validation Score')#, yerr = val_stds, capsize = 3,ecolor='black')\n",
    "        ax.set_xticks(gscv_output[param].unique())\n",
    "        #ax.set_ylim(0.82,0.92)\n",
    "        \n",
    "    ax.set_xlabel('Value')\n",
    "    ax.set_ylabel('Mean Accuracy')\n",
    "    ax.set_title(param)\n",
    "    #ax.legend()\n",
    "    \n",
    "plt.suptitle('Parameter Value vs. Validation Score')\n",
    "plt.tight_layout()\n",
    "\n",
    "#plt.savefig('./figures/GSCVout.pdf', dpi=300, bbox_inches = 'tight')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3684ffdd",
   "metadata": {},
   "source": [
    "### Check for Over-Fitting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3be3f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate simple cross validations\n",
    "#gscv_cv = cross_validate(gscv, X_train, y_train, cv=5, return_train_score=True)\n",
    "selected_cv = cross_validate(selected, X_train, y_train, cv=5, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09b1939",
   "metadata": {},
   "outputs": [],
   "source": [
    "if gscv_params != selected_params and showGSCV:\n",
    "    fig = plt.figure(figsize=(12,4))\n",
    "else:\n",
    "    fig = plt.figure(figsize=(6,4))\n",
    "\n",
    "xlabels = ['1st', '2nd', '3rd', '4th', '5th']\n",
    "x_axis_locs = np.arange(len(xlabels))\n",
    "\n",
    "if gscv_params != selected_params and showGSCV:\n",
    "    ax1 = fig.add_subplot(121)\n",
    "else:\n",
    "    ax1 = fig.add_subplot(111)\n",
    "\n",
    "\n",
    "ax1.bar(x_axis_locs-.21, selected_cv['train_score'], width=.4, label = 'Training Score')\n",
    "ax1.bar(x_axis_locs+.21, selected_cv['test_score'], width=.4, label = 'Validation Score')\n",
    "\n",
    "ax1.set_xticks(x_axis_locs, xlabels)\n",
    "ax1.set_xlabel('Fold Number', fontsize=14)\n",
    "ax1.set_ylabel('Accuracy', fontsize=14)\n",
    "if gscv_params != selected_params and showGSCV:\n",
    "    ax1.set_title('Selected Best Parameters')\n",
    "else:\n",
    "    ax1.set_title('Training and Validation for Simple Cross-Validation')\n",
    "ax1.set_ylim(0,1.05)\n",
    "ax1.legend()\n",
    "\n",
    "if gscv_params != selected_params and showGSCV:\n",
    "    ax2 = fig.add_subplot(122)\n",
    "    ax2.bar(x_axis_locs-.21, gscv_cv['train_score'], width=.4, label = 'Training Score')\n",
    "    ax2.bar(x_axis_locs+.21, gscv_cv['test_score'], width=.4, label = 'Validation Score')\n",
    "    \n",
    "    ax2.set_xticks(x_axis_locs, xlabels)\n",
    "    ax2.set_xlabel('Fold Number', fontsize=14)\n",
    "    ax2.set_ylabel('Accuracy', fontsize=14)\n",
    "    ax2.set_title('Grid Search CV Best Parameters')\n",
    "    ax2.set_ylim(0,1.05)\n",
    "    ax2.legend()\n",
    "\n",
    "\n",
    "if gscv_params != selected_params and showGSCV:\n",
    "    plt.suptitle('Training and Validation for Simple CV')\n",
    "plt.tight_layout()\n",
    "\n",
    "#plt.savefig('./figures/SelectedBarChart.pdf', dpi=300, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c5ae95",
   "metadata": {},
   "source": [
    "### Feature Importances plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b6ff4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected.fit(red_X,red_y)\n",
    "if gscv_params != selected_params and showGSCV:\n",
    "    gscv.fit(red_X,red_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebe2571",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected.fit(red_X,red_y)\n",
    "feature_importances_plot(selected, red_X, title = 'Feature Importances for Selected Parameters', ymax = 1)\n",
    "# plt.savefig('./figures/FI_selected.png', dpi=300, bbox_inches = 'tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe46767f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if gscv_params != selected_params and showGSCV:\n",
    "    feature_importances_plot(gscv, red_X, title = 'Feature Importances for GSCV Parameters',ymax = 1)\n",
    "#     plt.savefig('./figures/FI_gscv.png', dpi=300, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6d758c",
   "metadata": {},
   "source": [
    "### Averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d909283",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing n_estimators from dictionary so we can make a single tree with the same other parameters\n",
    "tree_params = selected_params.copy()\n",
    "del tree_params[\"n_estimators\"]\n",
    "del tree_params[\"max_samples\"]\n",
    "tree_params\n",
    "\n",
    "clf_tree = tree.DecisionTreeClassifier(**tree_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3734e3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_runs = 5\n",
    "\n",
    "selected_values = []\n",
    "tree_values = []\n",
    "if gscv_params != selected_params and showGSCV:\n",
    "    gscv_values = []\n",
    "    \n",
    "for i in range(n_runs):\n",
    "    X_train_avg, X_test_avg, y_train_avg, y_test_avg = resplit(red_X,red_y)\n",
    "#     print('split')\n",
    "    selected.fit(X_train_avg, y_train_avg)\n",
    "#     print('selected trained')\n",
    "#     print('gscv trained')\n",
    "    tree_clf.fit(X_train_avg, y_train_avg)\n",
    "#     print('tree trained')\n",
    "\n",
    "    \n",
    "    if gscv_params != selected_params and showGSCV:\n",
    "        gscv.fit(X_train_avg, y_train_avg)\n",
    "        gscv_values.append(gscv.score(X_test_avg, y_test_avg))\n",
    "    \n",
    "    selected_values.append(selected.score(X_test_avg, y_test_avg))\n",
    "    tree_values.append(tree_clf.score(X_test_avg, y_test_avg))\n",
    "    \n",
    "    print('Run '+str(i+1)+' complete')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031cf5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_values = np.asarray(selected_values)\n",
    "if gscv_params != selected_params and showGSCV:\n",
    "    gscv_values = np.asarray(gscv_values)\n",
    "tree_values = np.asarray(tree_values)\n",
    "\n",
    "print(\"Selected Params: %0.5f accuracy +/- %0.5f over %d runs\" % (selected_values.mean(), selected_values.std(), n_runs))\n",
    "if gscv_params != selected_params and showGSCV:\n",
    "    print(\"GSCV Params: %0.5f accuracy +/- %0.5f over %d runs\" % (gscv_values.mean(), gscv_values.std(), n_runs))\n",
    "print(\"Single Tree Params: %0.5f accuracy +/- %0.5f over %d runs\" % (tree_values.mean(), tree_values.std(), n_runs))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5874d7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.bar([0],[selected_values.mean()], yerr = [selected_values.std()],capsize = 3)\n",
    "if gscv_params != selected_params and showGSCV:\n",
    "    plt.bar([1],[gscv_values.mean()], yerr = [gscv_values.std()],capsize = 3)\n",
    "    plt.bar([2],[tree_values.mean()], yerr = [tree_values.std()],capsize = 3)\n",
    "else:\n",
    "    plt.bar([1],[tree_values.mean()], yerr = [tree_values.std()],capsize = 3)\n",
    "\n",
    "xlabels = ['Selected', 'Base Tree']\n",
    "if gscv_params != selected_params and showGSCV:\n",
    "    xlabels = ['Selected', 'GSCV', 'Base Tree']\n",
    "\n",
    "x_axis_locs = np.arange(len(xlabels))\n",
    "plt.xticks(x_axis_locs, xlabels)\n",
    "\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0,1)\n",
    "plt.title('Mean Test Accuracy Over %d Runs' % (n_runs))\n",
    "#plt.legend();\n",
    "\n",
    "# plt.savefig('./figures/means.pdf', dpi=300, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf89f68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
